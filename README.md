# CS231N



Assignments download : http://cs231n.stanford.edu/assignments/2017/



# Assignment1



## knn

![image-20211007144803236](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211007144803236.png)

```
Got 141 / 500 correct => accuracy: 0.282000
```



## SVM

![image-20211007165710066](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211007165710066.png)



## Softmax

visualize

![image-20211007191002604](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211007191002604.png)



result

```
softmax on raw pixels final test set accuracy: 0.359000
```



## NN

visualize

![image-20211007202314097](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211007202314097.png)



result

```
Test accuracy:  0.516
```



## features

I got the best net with lr:1e0, reg:1e-3



# Assigment2



## FCN

![image-20211008221904068](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211008221904068.png)



```
Validation set accuracy:  0.553
Test set accuracy:  0.526
```



## BN

![image-20211009212011165](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211009212011165.png)



batch normalization model could be much more robust to bad initialization



## dropout

![image-20211009220908231](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211009220908231.png)

dropout can prevent overfitting



## CNN

in small dataset

![image-20211011101142363](https://cdn.jsdelivr.net/gh/JudgementH/image-host/md/image-20211011101142363.png)

in big dataset

```
train acc: 0.579000; val_acc: 0.542000
```